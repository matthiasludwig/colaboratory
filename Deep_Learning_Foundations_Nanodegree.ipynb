{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep Learning Foundations Nanodegree.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "ym9D8-P3jJCk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Introductions"
      ]
    },
    {
      "metadata": {
        "id": "Ahm0DG1cyqdO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The Deep Learning Foundation Program is divided into **six chapters**, some of which including a project to complete:\n",
        "\n",
        "\n",
        "1.   Introductions\n",
        "2.   Neural Networks (**P1: Your first neural network**)\n",
        "3.   Convolutional Neural Networks (**P2: Dog Breed Classifier**)\n",
        "4.   Recurrent Neural Networks (**P3: Generate TV Scripts**)\n",
        "5.   Generative Adversarial Networks (**P4: Generate Faces**)\n",
        "6.   Deep Reinforcement Learning (**P5: Teach a Quadcopter to Fly**)\n",
        "\n",
        "**Machine Learning:**\n",
        "* Supervised (Feedback)\n",
        "* Unsupervised (No labels)\n",
        "* Reinforcement Learning (Feedback at the end)\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Anaconda\n",
        "Conda is a package manager that organizes dependencies in environments\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "conda create -n name packages=3       # Creates a new environment\n",
        "conda env list                        # Lists all environments\n",
        "source activate name                  # Activates an environment\n",
        "  conda install numpy pandas ...      # Installs packages inside the environment\n",
        "  conda list                          # Lists all packages installed in the environment\n",
        "  conda env export > environment.yaml # Exports all depencencies into a yaml file\n",
        "conda env create -f environment.yaml  # Creates a new environment from the yaml file\n",
        "conda env remove -n name              # Remove conda env\n",
        "```\n"
      ]
    },
    {
      "metadata": {
        "id": "M8b5SqkDBCsi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Jupyter\n",
        "A notebook is a web appplication that allows you to combine explanatory text, math equations, code and visualizations all in one easily sharable document.\n",
        "It is an example of [literate programming](http://www.literateprogramming.com/)\n",
        "\n",
        "### How Jupyter works:\n",
        "\n",
        "![explanation of how jupyter notebooks work](https://jupyter.readthedocs.io/en/latest/_images/notebook_components.png)"
      ]
    },
    {
      "metadata": {
        "id": "tE-d5FOvBLu0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Matrix Math and Numpy Refresher\n",
        "### Data Dimensions\n",
        "**Scalar:** Simplest shape | 0 dimsension\n",
        "**Vectors:** Row or Column vectors | 1 dimesion = length\n",
        "**Matrices:** 2d Vector | 2 dimensions\n",
        "**Tensors:** n-dimensional tensor\n",
        "\n",
        "Axy = x is the row and y is the column.\n",
        "\n",
        "### Numpy\n",
        "Written in C to perform fast mathematical operations."
      ]
    },
    {
      "metadata": {
        "id": "XMeaagt28Z-A",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "849e9c4e-f12f-4fd3-a452-c040350b7ba3",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525981448657,
          "user_tz": -120,
          "elapsed": 784,
          "user": {
            "displayName": "Matthias Ludwig",
            "photoUrl": "//lh3.googleusercontent.com/-Cacxebueg8s/AAAAAAAAAAI/AAAAAAAAAM8/S7I83k3nq90/s50-c-k-no/photo.jpg",
            "userId": "109901656152479831667"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "s = np.array(5)        # Scalar\n",
        "s.shape                # () since it is a scalar\n",
        "\n",
        "v = np.array([1,2,3])  # Vector\n",
        "v.shape                # (3,)\n",
        "v[1]                   # 2\n",
        "v[1:]                  # 2,3 | Access elements from the second one on\n",
        "\n",
        "m = np.array([[1,2,3], [4,5,6], [7,8,9]])\n",
        "m.shape                # (3,3)\n",
        "\n",
        "t = np.array([[[[1],[2]],[[3],[4]],[[5],[6]]],[[[7],[8]],[[9],[10]],[[11],[12]]],[[[13],[14]],[[15],[16]],[[17],[17]]]])\n",
        "t.shape                # (3,3,2,1)\n",
        "\n",
        "v.reshape(1,3)         # Change the shape\n",
        "v = v[:, None]         # More experienced reshaping\n",
        "v = v[None,:]\n",
        "v"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[1],\n",
              "        [2],\n",
              "        [3]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "GQ-MnqWR-33Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Element-wise Matrix Operations\n",
        "Treat the items in the matrix individually and perform the same operation on each one.\n",
        "Matrices have to have the same shape."
      ]
    },
    {
      "metadata": {
        "id": "j63fjn-u9Fdg",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "bab5fc50-1cc7-404b-f50c-e44166d0fc79",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523904757908,
          "user_tz": -120,
          "elapsed": 624,
          "user": {
            "displayName": "Matthias Ludwig",
            "photoUrl": "//lh3.googleusercontent.com/-Cacxebueg8s/AAAAAAAAAAI/AAAAAAAAAM8/S7I83k3nq90/s50-c-k-no/photo.jpg",
            "userId": "109901656152479831667"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "values = [1,2,3,4,5]\n",
        "values = np.array(values) + 5\n",
        "print(values)            # [6,7,8,9,10]\n",
        "\n",
        "values = np.multiply(values, 5)\n",
        "print(values)            # [30,35,40,50]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 6  7  8  9 10]\n",
            "[30 35 40 45 50]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jWBGvQVEwFle",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Matrix Multiplication\n",
        "Matrices don't have to have the same shape.\n",
        "Rows of the first Matrix and the columns of the second matrix. (Taking the Dot Product multiple times)\n",
        "\n",
        "#### Import Reminders about Matrix Multiplication\n",
        "* Number of columns in the left matrix must be equal to the number of rows in the second matrix. (2x3 and 3x2) (RowsXColumns)\n",
        "* The Result will have the same number of rows as the left matrix and the same number of columns as the right matrix.\n",
        "* Order matters. A*B != B*A\n",
        "* The data in the left should be ordered in rows and in columns in the left\n",
        "\n",
        "#### Dot Product\n",
        "Multiply the corresponding elements of each vector. Then we add up all the results."
      ]
    },
    {
      "metadata": {
        "id": "vu6RHdibyg5K",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### NumPy Matrix Multiplication\n",
        "\n",
        "**Element-wise** Multiplication: Using the * or multiply function:"
      ]
    },
    {
      "metadata": {
        "id": "MAYmkPD1zI5Q",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "4dc4170a-42a8-40e6-f109-2fe5ee34615e",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525722900028,
          "user_tz": -120,
          "elapsed": 654,
          "user": {
            "displayName": "Matthias Ludwig",
            "photoUrl": "//lh3.googleusercontent.com/-Cacxebueg8s/AAAAAAAAAAI/AAAAAAAAAM8/S7I83k3nq90/s50-c-k-no/photo.jpg",
            "userId": "109901656152479831667"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "multiple = np.array([[1,2,3],[4,5,6]])\n",
        "multiple\n",
        "\n",
        "new = multiple * 0.25\n",
        "new\n",
        "\n",
        "new * multiple\n",
        "\n",
        "np.multiply(multiple, new)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.25, 1.  , 2.25],\n",
              "       [4.  , 6.25, 9.  ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "gxXL22HE0xCa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Finding the **Matrix Product** using NumPy's matmul function:"
      ]
    },
    {
      "metadata": {
        "id": "7UmhIFVi03za",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "204ff9de-1b4c-4116-e173-b87ac5c2cf45",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523905467098,
          "user_tz": -120,
          "elapsed": 644,
          "user": {
            "displayName": "Matthias Ludwig",
            "photoUrl": "//lh3.googleusercontent.com/-Cacxebueg8s/AAAAAAAAAAI/AAAAAAAAAM8/S7I83k3nq90/s50-c-k-no/photo.jpg",
            "userId": "109901656152479831667"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "a = np.array([[1,2,3,4],[5,6,7,8]])\n",
        "a\n",
        "\n",
        "a.shape # (2,4)\n",
        "\n",
        "b = np.array([[1,2,3],[4,5,6],[7,8,9],[10,11,12]])\n",
        "b\n",
        "\n",
        "b.shape # (4,3)\n",
        "\n",
        "c = np.matmul(a,b)\n",
        "c\n",
        "\n",
        "c.shape # 2,3"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "id": "guqggPPA2KLU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "NumPy's **dot function** can be identical to matmul (if the matrices are 2-dimensional)"
      ]
    },
    {
      "metadata": {
        "id": "YNgNPNR92ZA6",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "2ff419d2-188f-433f-8424-ded97334ed49",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523905775476,
          "user_tz": -120,
          "elapsed": 416,
          "user": {
            "displayName": "Matthias Ludwig",
            "photoUrl": "//lh3.googleusercontent.com/-Cacxebueg8s/AAAAAAAAAAI/AAAAAAAAAM8/S7I83k3nq90/s50-c-k-no/photo.jpg",
            "userId": "109901656152479831667"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "a = np.array([[1,2],[3,4]])\n",
        "\n",
        "np.dot(a,a)\n",
        "a.dot(a)\n",
        "np.matmul(a,a)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 7, 10],\n",
              "       [15, 22]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "nDmenn7-5rsS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Transpose\n",
        "\n",
        "If the original Matrix was **not** a square the new transpose will have the dimensions swapped.\n",
        "Each feature is either in a row or a column.\n",
        "\n",
        "The option if you should transpose depends on the situation(!)\n",
        "\n",
        "**The only time you can safely use a tranpose if both data is arranged as rows**"
      ]
    },
    {
      "metadata": {
        "id": "pT3CyPSx7BOG",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "519ba9a9-52ef-48f5-d182-f38c343ad8c4",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523906814802,
          "user_tz": -120,
          "elapsed": 692,
          "user": {
            "displayName": "Matthias Ludwig",
            "photoUrl": "//lh3.googleusercontent.com/-Cacxebueg8s/AAAAAAAAAAI/AAAAAAAAAM8/S7I83k3nq90/s50-c-k-no/photo.jpg",
            "userId": "109901656152479831667"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "m = np.array([[1,2,3,4],[5,6,7,8],[9,10,11,12]])\n",
        "m\n",
        "\n",
        "m.T # Transpose of m"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1,  5,  9],\n",
              "       [ 2,  6, 10],\n",
              "       [ 3,  7, 11],\n",
              "       [ 4,  8, 12]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "metadata": {
        "id": "svSYT5JKA07m",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Neural Networks"
      ]
    },
    {
      "metadata": {
        "id": "yb6Q8vXOCq8K",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Lesson 1: Introduction to Neural Networks\n",
        "\n",
        "First idea is to compare Neural Networks to Linear Regression.\n",
        "\n",
        "W = Weights\n",
        "b = Bias\n",
        "x = Input\n",
        "y = label\n",
        "ÿ = Prediction\n",
        "\n",
        "### Perceptron\n",
        "\n",
        "**Comparison:** The Perceptron is the 2\\*Test + 1\\*Grades -18. Smaller Nodes are Inputs. Arrows are the Weights/Bias.\n",
        "\n",
        "![Image Perceptron](https://)\n",
        "\n",
        "#### Perceptron as Logical Operators\n",
        "\n",
        "**AND:** Only true if both INs are 1\n",
        "\n",
        "**OR:** If any of it's INs are 1\n",
        "\n",
        "**NOT:** Flips one of the Inputs\n",
        "\n",
        "**NAND:** Not and and\n",
        "\n",
        "The Perceptron Steps (Only works for linear function):\n"
      ]
    },
    {
      "metadata": {
        "id": "mhTfPfMlpc-S",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def perceptronStep(X, y, W, b, learn_rate = 0.01):\n",
        "    # Fill in code\n",
        "    for i in range(len(X)):\n",
        "        pred = prediction(X[i], W, b)\n",
        "        if y[i] - pred == 1:\n",
        "            W[0] += X[i][0] * learn_rate\n",
        "            W[1] += X[i][1] * learn_rate\n",
        "            b += learn_rate\n",
        "        if y[i] - pred == -1:\n",
        "            W[0] -= X[i][0] * learn_rate\n",
        "            W[1] -= X[i][1] * learn_rate\n",
        "            b -= learn_rate\n",
        "    return W, b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tRu6T9Ptp6xq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Error Functions\n",
        "\n",
        "* Minimizing the Error functions => Avoid local minimum. (Gradient Descent)\n",
        "* Error functions needs to be differentiable and continuous.\n",
        "\n",
        "**Goal:** Finding the way to minimize the Loss the fastest. The challenge is not to get stuck in a local minimum.\n",
        "Correctly classified points should carry a small Error. Not correctly classified points should carry a high penalty.\n",
        "\n",
        "**Prediction:** Discrete would be: Yes/no. Continious would be 0-100% likelyhood of something:\n",
        "* **Sigmoid:** Change the Activation function from Step function to sigmoid. 1/(1+e^-x)\n",
        "* **Softmax:** Classification Problems. The probabilities across all options have to add to 1. e^Zi / e^Zn\n",
        "* **One-Hot Encoding:** Inputvariables. One variable for each class. Each class has a column with either 0 or 1. So the value for each element is for example [0,0,1]"
      ]
    },
    {
      "metadata": {
        "id": "Sf1_z6Sl2qu2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Maximum Probability\n",
        "\n",
        "All Probabilities of each points multiplied. Gives the Probabilities that these points are the respective colors. The goal then becomes to maximize the likelyhood.\n",
        "* Increasing the probability => Deceasing the error\n",
        "* Going from products to sums: log. Becasue log(ab) = log(a) + log(b). All negative numbers => -ln(x)"
      ]
    },
    {
      "metadata": {
        "id": "s2XsTXpZ2t3A",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Cross-Entropy\n",
        "\n",
        "=> -ln(x).\n",
        "\n",
        "Good model gives a small Cross Entropy, A bad model gives a high Cross Entropy.\n",
        "\n",
        "Cross entropy says if a bunch of events and a bunch of probabilities, how likely is it that those events happen based on the probabilities?\n",
        "\n",
        "* Very likely: Small CE\n",
        "* Very unlikely: Big CE\n",
        "\n",
        "All probabilities of all Ys adds up to 1.\n",
        "\n",
        "**CE:** Gives how similiar two vectors are."
      ]
    },
    {
      "metadata": {
        "id": "I4uJZ0kE2CvG",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "48b892de-d70a-48c2-ce21-ce87c0ee094d",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526225112813,
          "user_tz": -120,
          "elapsed": 677,
          "user": {
            "displayName": "Matthias Ludwig",
            "photoUrl": "//lh3.googleusercontent.com/-Cacxebueg8s/AAAAAAAAAAI/AAAAAAAAAM8/S7I83k3nq90/s50-c-k-no/photo.jpg",
            "userId": "109901656152479831667"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "L = [1,0,1,1]\n",
        "P = [0.4,0.6,0.1,0.5]\n",
        "\n",
        "# Write a function that takes as input two lists Y, P,\n",
        "# and returns the float corresponding to their cross-entropy.\n",
        "def cross_entropy(Y, P):\n",
        "    \n",
        "    result = 0\n",
        "    \n",
        "    for y,p in zip(Y,P):\n",
        "        if y == 0:\n",
        "            result += np.log(1 - p)\n",
        "        else:\n",
        "            result += np.log(p)\n",
        "    \n",
        "    return result * (-1)\n",
        "  \n",
        "print(cross_entropy(L,P))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4.828313737302301\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "twa_vpQp2bxy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Multi-Class Cross Entropy\n",
        "\n",
        "**CE:** -Ei Ej yij ln(pij)\n",
        "\n",
        "A higher CE correlates to a lower Probability of this event happening (and vice versa)"
      ]
    },
    {
      "metadata": {
        "id": "VAar5B9P3hMq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Gradient Descent (Step)\n",
        "\n",
        "From the Error function through Gradient Descent a smaller Error function is searched for.\n",
        "\n",
        "Negative of the Gradient of the Error function leads us to the fastest way *\"down\"*. (Times a small learning rate)\n",
        "\n",
        "The **Derivative of the Sigmoid function** is: s(x) * (1-s(x))\n",
        "\n",
        "The **Derivative of the Error function** is: -(y - ÿ)(x1,...,xn,1)\n",
        "\n",
        "#### Step\n",
        "\n",
        "w'i <- wi + alpha(y-ÿ)xi (where alpha is the learning rate **and** 1/m * alpha)\n",
        "\n",
        "The update of the bias is similiar.\n",
        "\n",
        "\n",
        "#### Pseudo Code\n",
        "\n",
        "1. Start with random weights\n",
        "2. For every point\n",
        "\n",
        "  2.1 For i = i...n\n",
        "  \n",
        "    2.1.1 Update w'i <- wi - alpha(ÿ-y)xi\n",
        "    \n",
        "    2.2.2 Update b' <- b - alpha(ÿ-y)\n",
        "3. Repeat until the error is small\n",
        "\n",
        "(How many times = epochs)"
      ]
    },
    {
      "metadata": {
        "id": "3z7Q45NvDJp0",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Activation (sigmoid) function\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def output_formula(features, weights, bias):\n",
        "    return sigmoid(np.dot(features, weights) + bias)\n",
        "\n",
        "def error_formula(y, output):\n",
        "    return - y*np.log(output) - (1 - y) * np.log(1-output)\n",
        "\n",
        "def update_weights(x, y, weights, bias, learnrate):\n",
        "    output = output_formula(x, weights, bias)\n",
        "    d_error = -(y - output)\n",
        "    weights -= learnrate * d_error * x\n",
        "    bias -= learnrate * d_error\n",
        "    return weights, bias"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wRXWZOU4HMhC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Neural Network Architecture\n",
        "\n",
        "**Non-linear Models:** The line seperating two point groups will not be linear anymore this is where Neural Networks come into play\n",
        "\n",
        "=> Combining two linear models. Two probabilies via the sigmoid function. Adding two linear models to obtain a third model.\n",
        "\n",
        "* Input Layer (containts the inputs x1, x2,..., xn)\n",
        "* Hidden Layer\n",
        "* Output Layer (non-linear space)\n",
        "\n",
        "**Multi-class problems** have more Output Layers\n",
        "\n",
        "**More Hidden Layers:** Deep(er) Neural Network.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "RpVaQDWmb6-d",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Feedforward\n",
        "\n",
        "This is the process of neural networks use to turn the input into an output.\n",
        "Through the weights the different inputs get a stronger emphasis.\n",
        "\n",
        "Input vector -> Apply a sequence of linear functions and sigmoid functions to get a highly non-linear output layer."
      ]
    },
    {
      "metadata": {
        "id": "YBX5q9wLdEi4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Backpropagation\n",
        "\n",
        "E(W) = 1/m E yi ln(ÿi) + (1 - yi)ln(1 - ÿi)\n",
        "\n",
        "* Doing a feedforward operation\n",
        "* Comparing the output to the desired output (y - ÿ)\n",
        "* Calculating the Error\n",
        "* Running the feedforward operation backwards to spread the error to each of the weights\n",
        "* Use this to update the weights and get a better model\n",
        "* Repeat this process\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "NxmBDCO5hWXG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Lesson 2: Implementing Gradient Descent"
      ]
    },
    {
      "metadata": {
        "id": "CmLp-Tx35x97",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In the last chapter we used the log-loss function. There are many other error functions used for neural networks. One is called the mean squared error: It is the mean of the squares of the differences between the predictions and the labels.\n",
        "\n",
        "**SSE:** E = 1/2 EE (yj - ÿj)^2\n",
        "\n",
        "**Caveats:** We can end up in a local minima. That happens if the weights are initialized with the wrong values.\n",
        "\n",
        "The **derivative of the Error** with respect to wi is: - (y - ÿ)f'(h)xi"
      ]
    },
    {
      "metadata": {
        "id": "fA4kOF9It1Xm",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d2e7d29b-28d9-4e1a-efc2-a972cb4d5aa9",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526225641738,
          "user_tz": -120,
          "elapsed": 576,
          "user": {
            "displayName": "Matthias Ludwig",
            "photoUrl": "//lh3.googleusercontent.com/-Cacxebueg8s/AAAAAAAAAAI/AAAAAAAAAM8/S7I83k3nq90/s50-c-k-no/photo.jpg",
            "userId": "109901656152479831667"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Defining the sigmoid function for activations\n",
        "def sigmoid(x):\n",
        "    return 1/(1+np.exp(-x))\n",
        "\n",
        "# Derivative of the sigmoid function\n",
        "def sigmoid_prime(x):\n",
        "    return sigmoid(x) * (1 - sigmoid(x))\n",
        "\n",
        "# Input data\n",
        "x = np.array([0.1, 0.3])\n",
        "# Target\n",
        "y = 0.2\n",
        "# Input to output weights\n",
        "weights = np.array([-0.8, 0.5])\n",
        "\n",
        "# The learning rate, eta in the weight step equation\n",
        "learnrate = 0.5\n",
        "\n",
        "# the linear combination performed by the node (h in f(h) and f'(h))\n",
        "h = x[0]*weights[0] + x[1]*weights[1]\n",
        "# or h = np.dot(x, weights)\n",
        "\n",
        "# The neural network output (y-hat)\n",
        "nn_output = sigmoid(h)\n",
        "\n",
        "# output error (y - y-hat)\n",
        "error = y - nn_output\n",
        "\n",
        "# output gradient (f'(h))\n",
        "output_grad = sigmoid_prime(h)\n",
        "\n",
        "# error term (lowercase delta)\n",
        "error_term = error * output_grad\n",
        "\n",
        "# Gradient descent step \n",
        "del_w = [ learnrate * error_term * x[0],\n",
        "          learnrate * error_term * x[1]]\n",
        "# or del_w = learnrate * error_term * x\n",
        "\n",
        "print(del_w)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-0.003963803079006883, -0.011891409237020648]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "B_cGkjazvy-u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Here's the general algorithm for updating the weights with gradient descent:\n",
        "\n",
        "Set the weight step to zero: Δwi=0\\Delta w_i = 0Δwi​=0\n",
        "\n",
        "**For each record in the training data:**\n",
        "\n",
        "* Make a forward pass through the network, calculating the output y^=f(∑iwixi)\\hat y = f(\\sum_i w_i x_i)y^​=f(∑i​wi​xi​)\n",
        "* Calculate the error term for the output unit, δ=(y−y^)∗f′(∑iwixi)\\delta = (y - \\hat y) * f'(\\sum_i w_i x_i)δ=(y−y^​)∗f′(∑i​wi​xi​)\n",
        "* Update the weight step Δwi=Δwi+δxi\\Delta w_i = \\Delta w_i + \\delta x_iΔwi​=Δwi​+δxi​\n",
        "* Update the weights wi=wi+ηΔwi/mw_i = w_i + \\eta \\Delta w_i / mwi​=wi​+ηΔwi​/m where η\\etaη is the learning rate and mmm is the number of records. Here we're averaging the weight steps to help reduce any large variations in the training data.\n",
        "\n",
        "Repeat for e epochs.\n",
        "\n",
        "**Example with Epochs:**\n"
      ]
    },
    {
      "metadata": {
        "id": "hr1cB50D0UZj",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from data_prep import features, targets, features_test, targets_test\n",
        "\n",
        "\n",
        "def sigmoid(x):\n",
        "    \"\"\"\n",
        "    Calculate sigmoid\n",
        "    \"\"\"\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "# TODO: We haven't provided the sigmoid_prime function like we did in\n",
        "#       the previous lesson to encourage you to come up with a more\n",
        "#       efficient solution. If you need a hint, check out the comments\n",
        "#       in solution.py from the previous lecture.\n",
        "\n",
        "# Use to same seed to make debugging easier\n",
        "np.random.seed(42)\n",
        "\n",
        "n_records, n_features = features.shape\n",
        "last_loss = None\n",
        "\n",
        "# Initialize weights\n",
        "weights = np.random.normal(scale=1 / n_features**.5, size=n_features)\n",
        "\n",
        "# Neural Network hyperparameters\n",
        "epochs = 1000\n",
        "learnrate = 0.5\n",
        "\n",
        "for e in range(epochs):\n",
        "    del_w = np.zeros(weights.shape)\n",
        "    for x, y in zip(features.values, targets):\n",
        "        # Loop through all records, x is the input, y is the target\n",
        "\n",
        "        # Note: We haven't included the h variable from the previous\n",
        "        #       lesson. You can add it if you want, or you can calculate\n",
        "        #       the h together with the output\n",
        "\n",
        "        # TODO: Calculate the output\n",
        "        h = np.dot(x, weights)\n",
        "        \n",
        "        output = sigmoid(h)\n",
        "\n",
        "        # TODO: Calculate the error\n",
        "        error = y - output\n",
        "\n",
        "        # TODO: Calculate the error term\n",
        "        #output_grad = output * (1 - output)\n",
        "        \n",
        "        error_term = error * output * (1 - output)\n",
        "\n",
        "        # TODO: Calculate the change in weights for this sample\n",
        "        #       and add it to the total weight change\n",
        "        del_w += error_term * x\n",
        "\n",
        "    # TODO: Update weights using the learning rate and the average change in weights\n",
        "    weights += learnrate * del_w / n_records\n",
        "\n",
        "    # Printing out the mean square error on the training set\n",
        "    if e % (epochs / 10) == 0:\n",
        "        out = sigmoid(np.dot(features, weights))\n",
        "        loss = np.mean((out - targets) ** 2)\n",
        "        if last_loss and last_loss < loss:\n",
        "            print(\"Train loss: \", loss, \"  WARNING - Loss Increasing\")\n",
        "        else:\n",
        "            print(\"Train loss: \", loss)\n",
        "        last_loss = loss\n",
        "\n",
        "\n",
        "# Calculate accuracy on test data\n",
        "tes_out = sigmoid(np.dot(features_test, weights))\n",
        "predictions = tes_out > 0.5\n",
        "accuracy = np.mean(predictions == targets_test)\n",
        "print(\"Prediction accuracy: {:.3f}\".format(accuracy))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "naiGag7S10mw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Multilayer Preceptrons\n",
        "\n",
        "With hidden units, the weights between them will require two incides: wij, where i denotes input units and j are the hidden units\n",
        "\n",
        "#### Making a column vector\n",
        "\n",
        "It's possible to get the transpose of an array like so arr.T but for a 1D array, the transpose will return a row vector. Instead use arr[:,None] to create a column vector:"
      ]
    },
    {
      "metadata": {
        "id": "utxxEpMm56O2",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "f02e92ef-be94-4e98-92b9-95151e6af3b7",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526154733565,
          "user_tz": -120,
          "elapsed": 567,
          "user": {
            "displayName": "Matthias Ludwig",
            "photoUrl": "//lh3.googleusercontent.com/-Cacxebueg8s/AAAAAAAAAAI/AAAAAAAAAM8/S7I83k3nq90/s50-c-k-no/photo.jpg",
            "userId": "109901656152479831667"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "features = np.array([0.49671415, -0.1382643 , 0.64768854])\n",
        "\n",
        "print(features)\n",
        "# array([ 0.49671415, -0.1382643 ,  0.64768854])\n",
        "\n",
        "print(features.T)\n",
        "# array([ 0.49671415, -0.1382643 ,  0.64768854])\n",
        "\n",
        "print(features[:, None])\n",
        "# array([[ 0.49671415],\n",
        "#       [-0.1382643 ],\n",
        "#       [ 0.64768854]])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0.49671415 -0.1382643   0.64768854]\n",
            "[ 0.49671415 -0.1382643   0.64768854]\n",
            "[[ 0.49671415]\n",
            " [-0.1382643 ]\n",
            " [ 0.64768854]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "X2lCWzD86701",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Backpropagation\n",
        "\n",
        "Using the chain rule to find the error with respect to the weights connecting the input layer to the hidden layer (for a two layer network)."
      ]
    },
    {
      "metadata": {
        "id": "WH9KRveU_a77",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "724aa948-2875-40cc-ea16-23a167a2216b",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526318920581,
          "user_tz": -120,
          "elapsed": 779,
          "user": {
            "displayName": "Matthias Ludwig",
            "photoUrl": "//lh3.googleusercontent.com/-Cacxebueg8s/AAAAAAAAAAI/AAAAAAAAAM8/S7I83k3nq90/s50-c-k-no/photo.jpg",
            "userId": "109901656152479831667"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def sigmoid(x):\n",
        "    \"\"\"\n",
        "    Calculate sigmoid\n",
        "    \"\"\"\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "\n",
        "x = np.array([0.5, 0.1, -0.2])\n",
        "target = 0.6\n",
        "learnrate = 0.5\n",
        "\n",
        "weights_input_hidden = np.array([[0.5, -0.6],\n",
        "                                 [0.1, -0.2],\n",
        "                                 [0.1, 0.7]])\n",
        "\n",
        "weights_hidden_output = np.array([0.1, -0.3])\n",
        "\n",
        "## Forward pass\n",
        "hidden_layer_input = np.dot(x, weights_input_hidden)\n",
        "hidden_layer_output = sigmoid(hidden_layer_input)\n",
        "\n",
        "output_layer_in = np.dot(hidden_layer_output, weights_hidden_output)\n",
        "output = sigmoid(output_layer_in)\n",
        "\n",
        "## Backwards pass\n",
        "## TODO: Calculate output error\n",
        "error = target - output\n",
        "\n",
        "# TODO: Calculate error term for output layer\n",
        "output_error_term = error * output * (1 - output)\n",
        "\n",
        "# TODO: Calculate error term for hidden layer\n",
        "hidden_error_term = np.dot(output_error_term, weights_hidden_output) * hidden_layer_output * (1 - hidden_layer_output)\n",
        "\n",
        "# TODO: Calculate change in weights for hidden layer to output layer\n",
        "delta_w_h_o = learnrate * output_error_term * hidden_layer_output\n",
        "\n",
        "# TODO: Calculate change in weights for input layer to hidden layer\n",
        "delta_w_i_h = learnrate * hidden_error_term * x[:, None]\n",
        "\n",
        "print('Change in weights for hidden layer to output layer:')\n",
        "print(delta_w_h_o)\n",
        "print('Change in weights for input layer to hidden layer:')\n",
        "print(delta_w_i_h)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Change in weights for hidden layer to output layer:\n",
            "[0.00804047 0.00555918]\n",
            "Change in weights for input layer to hidden layer:\n",
            "[[ 1.77005547e-04 -5.11178506e-04]\n",
            " [ 3.54011093e-05 -1.02235701e-04]\n",
            " [-7.08022187e-05  2.04471402e-04]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pYMPMva5BpDo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Implementing Backpropagation"
      ]
    },
    {
      "metadata": {
        "id": "Y9z6AT5GBsuL",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "03032ef5-7bdb-43ad-f62b-f086e0713470",
        "executionInfo": {
          "status": "error",
          "timestamp": 1526156729701,
          "user_tz": -120,
          "elapsed": 877,
          "user": {
            "displayName": "Matthias Ludwig",
            "photoUrl": "//lh3.googleusercontent.com/-Cacxebueg8s/AAAAAAAAAAI/AAAAAAAAAM8/S7I83k3nq90/s50-c-k-no/photo.jpg",
            "userId": "109901656152479831667"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from data_prep import features, targets, features_test, targets_test\n",
        "\n",
        "np.random.seed(21)\n",
        "\n",
        "def sigmoid(x):\n",
        "    \"\"\"\n",
        "    Calculate sigmoid\n",
        "    \"\"\"\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "\n",
        "# Hyperparameters\n",
        "n_hidden = 2  # number of hidden units\n",
        "epochs = 900\n",
        "learnrate = 0.005\n",
        "\n",
        "n_records, n_features = features.shape\n",
        "last_loss = None\n",
        "# Initialize weights\n",
        "weights_input_hidden = np.random.normal(scale=1 / n_features ** .5,\n",
        "                                        size=(n_features, n_hidden))\n",
        "weights_hidden_output = np.random.normal(scale=1 / n_features ** .5,\n",
        "                                         size=n_hidden)\n",
        "\n",
        "for e in range(epochs):\n",
        "    del_w_input_hidden = np.zeros(weights_input_hidden.shape)\n",
        "    del_w_hidden_output = np.zeros(weights_hidden_output.shape)\n",
        "    for x, y in zip(features.values, targets):\n",
        "        ## Forward pass ##\n",
        "        # TODO: Calculate the output\n",
        "        hidden_input = np.dot(x, weights_input_hidden)\n",
        "        hidden_output = sigmoid(hidden_input)\n",
        "        \n",
        "        input_for_output = np.dot(hidden_output, weights_hidden_output)\n",
        "        \n",
        "        output = sigmoid(input_for_output)\n",
        "\n",
        "        ## Backward pass ##\n",
        "        # TODO: Calculate the network's prediction error\n",
        "        error = y - output\n",
        "\n",
        "        # TODO: Calculate error term for the output unit\n",
        "        output_error_term = error * output * (1 - output)\n",
        "\n",
        "        ## propagate errors to hidden layer\n",
        "\n",
        "        # TODO: Calculate the hidden layer's contribution to the error\n",
        "        hidden_error = np.dot(output_error_term, weights_hidden_output)\n",
        "        \n",
        "        # TODO: Calculate the error term for the hidden layer\n",
        "        hidden_error_term = hidden_error * hidden_output * (1 - hidden_output)\n",
        "        \n",
        "        # TODO: Update the change in weights\n",
        "        del_w_hidden_output += learnrate * output_error_term * hidden_output\n",
        "        del_w_input_hidden += learnrate * hidden_error_term * x[:, None]\n",
        "\n",
        "    # TODO: Update weights\n",
        "    weights_input_hidden += del_w_input_hidden\n",
        "    weights_hidden_output += del_w_hidden_output\n",
        "\n",
        "    # Printing out the mean square error on the training set\n",
        "    if e % (epochs / 10) == 0:\n",
        "        hidden_output = sigmoid(np.dot(x, weights_input_hidden))\n",
        "        out = sigmoid(np.dot(hidden_output,\n",
        "                             weights_hidden_output))\n",
        "        loss = np.mean((out - targets) ** 2)\n",
        "\n",
        "        if last_loss and last_loss < loss:\n",
        "            print(\"Train loss: \", loss, \"  WARNING - Loss Increasing\")\n",
        "        else:\n",
        "            print(\"Train loss: \", loss)\n",
        "        last_loss = loss\n",
        "\n",
        "# Calculate accuracy on test data\n",
        "hidden = sigmoid(np.dot(features_test, weights_input_hidden))\n",
        "out = sigmoid(np.dot(hidden, weights_hidden_output))\n",
        "predictions = out > 0.5\n",
        "accuracy = np.mean(predictions == targets_test)\n",
        "print(\"Prediction accuracy: {:.3f}\".format(accuracy))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-50c4f398dc71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdata_prep\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m21\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'data_prep'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "U_hxrg9NB9T8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Lesson 3: Training Neural Networks\n",
        "\n",
        "**Training set:** Model is trained with that without looking at the Testing set.\n",
        "\n",
        "**Testing set:** Testing the Model at the end (Re- Introduced)\n",
        "\n",
        "---\n",
        "\n",
        "**Overfitting:** Fit the data well, but it can not generalize. Error due to variance.\n",
        "\n",
        "**Underfitting:** Trying to kill godzilla with a flyswatter. Error due to bias.\n",
        "\n",
        "Both problems also correlate with a too simple/too complicated neural network architecture.\n",
        "We err on the side of an overly complicated model and then apply techniques to prevent overfitting.\n",
        "\n",
        "#### Early Stopping\n",
        "\n",
        "Underfitting: Training and Test errors are big\n",
        "Overfitting: Training Error is tiny and Testing Error Large\n",
        "\n",
        "--> Model Complexity Graph\n",
        "Testing Error increases with more Epochs\n",
        "Training Error decreases with the Epochs\n",
        "We need the point where the **Testing Error increases again** (Early Stopping)"
      ]
    },
    {
      "metadata": {
        "id": "uR09B3BoIxCQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Regularization\n",
        "\n",
        "When we apply sigmoid to 10x1 and 10x2 the function becomes steeper => Gradient Descent becomes harder.\n",
        "\n",
        "##### Punish large coefficients:\n",
        "**L1**: MSE + lamda * w1,...,wn (absolute values)\n",
        "* Good for features selection\n",
        "* Sparse Vectors. Small number of weights.\n",
        "\n",
        "**L2**: MSE + lamda * w1,...,wn (squared)\n",
        "* Normally better for Training Models\n",
        "* Does not favor small vectors"
      ]
    },
    {
      "metadata": {
        "id": "-mcqOyTIK61L",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Dropout\n",
        "\n",
        "One part of the network has large weights and dominates the training.\n",
        "**Sometimes during training some nodes are turned off.**\n",
        "Probability that each node will be dropped."
      ]
    },
    {
      "metadata": {
        "id": "dtOsW_6CMBNG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Vanishing Gradient\n",
        "\n",
        "**Hyperbolic Tangent Function:** e^x - e^x / e^x + e^x\n",
        "\n",
        "**Rectified Linear Unit (ReLU):** If Positive return x. If negative return 0."
      ]
    },
    {
      "metadata": {
        "id": "b3tqj2erM-oF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Batch vs. Stochastic Gradient Descent\n",
        "\n",
        "Number of steps in the gradient descent = Number of epochs.\n",
        "Epoch whole forward and backward pass for the data.\n",
        "\n",
        "**Stochastic Gradient Descent:** Small subset of the data. Batches of the whole data."
      ]
    },
    {
      "metadata": {
        "id": "nagicM9tOwWp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Learning Rate Decay\n",
        "\n",
        "Best: If steep: Long steps. If plaing: small steps.\n",
        "\n",
        "**Random Restart**: Gradient Descent from different locations.\n",
        "\n",
        "**Momentum**: Average of the last # steps. Beta between 0-1. Step(n) + b*Step(n-1) + ..."
      ]
    },
    {
      "metadata": {
        "id": "8Tuzf828KQI_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Lesson 6: Sentiment Analysis\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "l_cVM54HIwQ_",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "import sys\n",
        "import numpy as np\n",
        "\n",
        "# Encapsulate our neural network in a class\n",
        "class SentimentNetwork:\n",
        "    def __init__(self, reviews,labels,hidden_nodes = 10, learning_rate = 0.1):\n",
        "        \"\"\"Create a SentimenNetwork with the given settings\n",
        "        Args:\n",
        "            reviews(list) - List of reviews used for training\n",
        "            labels(list) - List of POSITIVE/NEGATIVE labels associated with the given reviews\n",
        "            hidden_nodes(int) - Number of nodes to create in the hidden layer\n",
        "            learning_rate(float) - Learning rate to use while training\n",
        "        \n",
        "        \"\"\"\n",
        "        # Assign a seed to our random number generator to ensure we get\n",
        "        # reproducable results during development \n",
        "        np.random.seed(1)\n",
        "\n",
        "        # process the reviews and their associated labels so that everything\n",
        "        # is ready for training\n",
        "        self.pre_process_data(reviews, labels)\n",
        "        \n",
        "        # Build the network to have the number of hidden nodes and the learning rate that\n",
        "        # were passed into this initializer. Make the same number of input nodes as\n",
        "        # there are vocabulary words and create a single output node.\n",
        "        self.init_network(len(self.review_vocab),hidden_nodes, 1, learning_rate)\n",
        "\n",
        "    def pre_process_data(self, reviews, labels):\n",
        "        \n",
        "        # populate review_vocab with all of the words in the given reviews\n",
        "        review_vocab = set()\n",
        "        for review in reviews:\n",
        "            for word in review.split(\" \"):\n",
        "                review_vocab.add(word)\n",
        "\n",
        "        # Convert the vocabulary set to a list so we can access words via indices\n",
        "        self.review_vocab = list(review_vocab)\n",
        "        \n",
        "        # populate label_vocab with all of the words in the given labels.\n",
        "        label_vocab = set()\n",
        "        for label in labels:\n",
        "            label_vocab.add(label)\n",
        "        \n",
        "        # Convert the label vocabulary set to a list so we can access labels via indices\n",
        "        self.label_vocab = list(label_vocab)\n",
        "        \n",
        "        # Store the sizes of the review and label vocabularies.\n",
        "        self.review_vocab_size = len(self.review_vocab)\n",
        "        self.label_vocab_size = len(self.label_vocab)\n",
        "        \n",
        "        # Create a dictionary of words in the vocabulary mapped to index positions\n",
        "        self.word2index = {}\n",
        "        for i, word in enumerate(self.review_vocab):\n",
        "            self.word2index[word] = i\n",
        "        \n",
        "        # Create a dictionary of labels mapped to index positions\n",
        "        self.label2index = {}\n",
        "        for i, label in enumerate(self.label_vocab):\n",
        "            self.label2index[label] = i\n",
        "        \n",
        "    def init_network(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n",
        "        # Set number of nodes in input, hidden and output layers.\n",
        "        self.input_nodes = input_nodes\n",
        "        self.hidden_nodes = hidden_nodes\n",
        "        self.output_nodes = output_nodes\n",
        "\n",
        "        # Store the learning rate\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "        # Initialize weights\n",
        "\n",
        "        # These are the weights between the input layer and the hidden layer.\n",
        "        self.weights_0_1 = np.zeros((self.input_nodes,self.hidden_nodes))\n",
        "    \n",
        "        # These are the weights between the hidden layer and the output layer.\n",
        "        self.weights_1_2 = np.random.normal(0.0, self.output_nodes**-0.5, \n",
        "                                                (self.hidden_nodes, self.output_nodes))\n",
        "        \n",
        "        # The input layer, a two-dimensional matrix with shape 1 x input_nodes\n",
        "        self.layer_0 = np.zeros((1,input_nodes))\n",
        "    \n",
        "    def update_input_layer(self,review):\n",
        "\n",
        "        # clear out previous state, reset the layer to be all 0s\n",
        "        self.layer_0 *= 0\n",
        "        \n",
        "        for word in review.split(\" \"):\n",
        "            # NOTE: This if-check was not in the version of this method created in Project 2,\n",
        "            #       and it appears in Andrew's Project 3 solution without explanation. \n",
        "            #       It simply ensures the word is actually a key in word2index before\n",
        "            #       accessing it, which is important because accessing an invalid key\n",
        "            #       with raise an exception in Python. This allows us to ignore unknown\n",
        "            #       words encountered in new reviews.\n",
        "            if(word in self.word2index.keys()):\n",
        "                self.layer_0[0][self.word2index[word]] += 1\n",
        "                \n",
        "    def get_target_for_label(self,label):\n",
        "        if(label == 'POSITIVE'):\n",
        "            return 1\n",
        "        else:\n",
        "            return 0\n",
        "        \n",
        "    def sigmoid(self,x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "    \n",
        "    def sigmoid_output_2_derivative(self,output):\n",
        "        return output * (1 - output)\n",
        "    \n",
        "    def train(self, training_reviews, training_labels):\n",
        "        \n",
        "        # make sure out we have a matching number of reviews and labels\n",
        "        assert(len(training_reviews) == len(training_labels))\n",
        "        \n",
        "        # Keep track of correct predictions to display accuracy during training \n",
        "        correct_so_far = 0\n",
        "\n",
        "        # Remember when we started for printing time statistics\n",
        "        start = time.time()\n",
        "        \n",
        "        # loop through all the given reviews and run a forward and backward pass,\n",
        "        # updating weights for every item\n",
        "        for i in range(len(training_reviews)):\n",
        "            \n",
        "            # Get the next review and its correct label\n",
        "            review = training_reviews[i]\n",
        "            label = training_labels[i]\n",
        "            \n",
        "            #### Implement the forward pass here ####\n",
        "            ### Forward pass ###\n",
        "\n",
        "            # Input Layer\n",
        "            self.update_input_layer(review)\n",
        "\n",
        "            # Hidden layer\n",
        "            layer_1 = self.layer_0.dot(self.weights_0_1)\n",
        "\n",
        "            # Output layer\n",
        "            layer_2 = self.sigmoid(layer_1.dot(self.weights_1_2))\n",
        "            \n",
        "            #### Implement the backward pass here ####\n",
        "            ### Backward pass ###\n",
        "\n",
        "            # Output error\n",
        "            layer_2_error = layer_2 - self.get_target_for_label(label) # Output layer error is the difference between desired target and actual output.\n",
        "            layer_2_delta = layer_2_error * self.sigmoid_output_2_derivative(layer_2)\n",
        "\n",
        "            # Backpropagated error\n",
        "            layer_1_error = layer_2_delta.dot(self.weights_1_2.T) # errors propagated to the hidden layer\n",
        "            layer_1_delta = layer_1_error # hidden layer gradients - no nonlinearity so it's the same as the error\n",
        "\n",
        "            # Update the weights\n",
        "            self.weights_1_2 -= layer_1.T.dot(layer_2_delta) * self.learning_rate # update hidden-to-output weights with gradient descent step\n",
        "            self.weights_0_1 -= self.layer_0.T.dot(layer_1_delta) * self.learning_rate # update input-to-hidden weights with gradient descent step\n",
        "\n",
        "            # Keep track of correct predictions.\n",
        "            if(layer_2 >= 0.5 and label == 'POSITIVE'):\n",
        "                correct_so_far += 1\n",
        "            elif(layer_2 < 0.5 and label == 'NEGATIVE'):\n",
        "                correct_so_far += 1\n",
        "            \n",
        "            # For debug purposes, print out our prediction accuracy and speed \n",
        "            # throughout the training process. \n",
        "            elapsed_time = float(time.time() - start)\n",
        "            reviews_per_second = i / elapsed_time if elapsed_time > 0 else 0\n",
        "            \n",
        "            sys.stdout.write(\"\\rProgress:\" + str(100 * i/float(len(training_reviews)))[:4] \\\n",
        "                             + \"% Speed(reviews/sec):\" + str(reviews_per_second)[0:5] \\\n",
        "                             + \" #Correct:\" + str(correct_so_far) + \" #Trained:\" + str(i+1) \\\n",
        "                             + \" Training Accuracy:\" + str(correct_so_far * 100 / float(i+1))[:4] + \"%\")\n",
        "            if(i % 2500 == 0):\n",
        "                print(\"\")\n",
        "    \n",
        "    def test(self, testing_reviews, testing_labels):\n",
        "        \"\"\"\n",
        "        Attempts to predict the labels for the given testing_reviews,\n",
        "        and uses the test_labels to calculate the accuracy of those predictions.\n",
        "        \"\"\"\n",
        "        \n",
        "        # keep track of how many correct predictions we make\n",
        "        correct = 0\n",
        "\n",
        "        # we'll time how many predictions per second we make\n",
        "        start = time.time()\n",
        "\n",
        "        # Loop through each of the given reviews and call run to predict\n",
        "        # its label. \n",
        "        for i in range(len(testing_reviews)):\n",
        "            pred = self.run(testing_reviews[i])\n",
        "            if(pred == testing_labels[i]):\n",
        "                correct += 1\n",
        "            \n",
        "            # For debug purposes, print out our prediction accuracy and speed \n",
        "            # throughout the prediction process. \n",
        "\n",
        "            elapsed_time = float(time.time() - start)\n",
        "            reviews_per_second = i / elapsed_time if elapsed_time > 0 else 0\n",
        "            \n",
        "            sys.stdout.write(\"\\rProgress:\" + str(100 * i/float(len(testing_reviews)))[:4] \\\n",
        "                             + \"% Speed(reviews/sec):\" + str(reviews_per_second)[0:5] \\\n",
        "                             + \" #Correct:\" + str(correct) + \" #Tested:\" + str(i+1) \\\n",
        "                             + \" Testing Accuracy:\" + str(correct * 100 / float(i+1))[:4] + \"%\")\n",
        "    \n",
        "    def run(self, review):\n",
        "        \"\"\"\n",
        "        Returns a POSITIVE or NEGATIVE prediction for the given review.\n",
        "        \"\"\"\n",
        "        # Run a forward pass through the network, like in the \"train\" function.\n",
        "        \n",
        "        # Input Layer\n",
        "        self.update_input_layer(review.lower())\n",
        "\n",
        "        # Hidden layer\n",
        "        layer_1 = self.layer_0.dot(self.weights_0_1)\n",
        "\n",
        "        # Output layer\n",
        "        layer_2 = self.sigmoid(layer_1.dot(self.weights_1_2))\n",
        "        \n",
        "        # Return POSITIVE for values above greater-than-or-equal-to 0.5 in the output layer;\n",
        "        # return NEGATIVE for other values\n",
        "        if(layer_2[0] >= 0.5):\n",
        "            return \"POSITIVE\"\n",
        "        else:\n",
        "            return \"NEGATIVE\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lVHy6qDns8Rs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Lesson 7: Keras\n",
        "\n",
        "Examples of packages for deep learning:\n",
        "\n",
        "* Keras\n",
        "* TensorFlow\n",
        "* Caffe\n",
        "* Theano\n",
        "* Scikit-learn\n",
        "* ..."
      ]
    },
    {
      "metadata": {
        "id": "h1OVnjb8tnTk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Creating a Sequential Model in Keras"
      ]
    },
    {
      "metadata": {
        "id": "W_IldXVBtmR0",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "2e0b621e-2dfc-4d44-b18c-4fde227f1d2b",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526320454690,
          "user_tz": -120,
          "elapsed": 658,
          "user": {
            "displayName": "Matthias Ludwig",
            "photoUrl": "//lh3.googleusercontent.com/-Cacxebueg8s/AAAAAAAAAAI/AAAAAAAAAM8/S7I83k3nq90/s50-c-k-no/photo.jpg",
            "userId": "109901656152479831667"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Activation\n",
        "\n",
        "# Layers\n",
        "## Fully connected layers\n",
        "## max pool layers\n",
        "## activation layers\n",
        "## and more\n",
        "\n",
        "# X has shape (num_rows, num_cols) where the training data is stored as row vectors\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=np.float32)\n",
        "\n",
        "# y must have an output vector for each input vector\n",
        "y = np.array([[0], [0], [0], [1]], dtype=np.float32)\n",
        "\n",
        "# Create the Sequential model\n",
        "model = Sequential()\n",
        "# The keras.models.Sequential class is a wrapper for the neural network model\n",
        "# that treats the network as a sequence of layers\n",
        "\n",
        "# 1st layer - Add an input layer of 32 nodes with the same input shape as X\n",
        "model.add(Dense(32, input_dim=X.shape[1]))\n",
        "\n",
        "# Add a softmax activation layer\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# 2nd layer - Add a fully connected output layer\n",
        "model.add(Dense(1))\n",
        "\n",
        "#Add a sigmoid activation layer\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "X"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 1.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "zXP72mPLu-jR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* Keras requires the input shape to be specified for the first layer. It will automatically infer the shape of all other layers\n",
        "* Activation is added after the layers\n",
        "* Compiling the Keras model calls the backend (tensorflow, theano, etc.) and binds the optimizer, loss function and other paramters required before the model can be run on any input data.\n",
        "* We specify the loss function to be *categorical_crossentropy*\n",
        "* and specify *adam* as the optimizer\n",
        "* also we specify what metrics we want to evaluate the model with"
      ]
    },
    {
      "metadata": {
        "id": "TaKhaBzgv0zl",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 1105
        },
        "outputId": "912a8084-358f-4410-e47e-d05a9dfd8522",
        "executionInfo": {
          "status": "error",
          "timestamp": 1526320287843,
          "user_tz": -120,
          "elapsed": 704,
          "user": {
            "displayName": "Matthias Ludwig",
            "photoUrl": "//lh3.googleusercontent.com/-Cacxebueg8s/AAAAAAAAAAI/AAAAAAAAAM8/S7I83k3nq90/s50-c-k-no/photo.jpg",
            "userId": "109901656152479831667"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics = [\"accuracy\"])\n",
        "\n",
        "# See the resulting model architecture with the following command\n",
        "model.summary()\n",
        "\n",
        "# Train with the fit() method\n",
        "\n",
        "model.fit(X, y, epochs=1000, verbose=0)\n",
        "\n",
        "# Evaluate the model\n",
        "\n",
        "model.evaluate()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_13 (Dense)             (None, 32)                96        \n",
            "_________________________________________________________________\n",
            "activation_13 (Activation)   (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 1)                 33        \n",
            "_________________________________________________________________\n",
            "activation_14 (Activation)   (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 129\n",
            "Trainable params: 129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-7930dfd07485>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Train with the fit() method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1000\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1628\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1629\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1630\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1631\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1632\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m   1491\u001b[0m         _check_loss_and_target_compatibility(y,\n\u001b[1;32m   1492\u001b[0m                                              \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_loss_fns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1493\u001b[0;31m                                              self._feed_output_shapes)\n\u001b[0m\u001b[1;32m   1494\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1495\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_check_loss_and_target_compatibility\u001b[0;34m(targets, loss_fns, output_shapes)\u001b[0m\n\u001b[1;32m    254\u001b[0m                 raise ValueError(\n\u001b[1;32m    255\u001b[0m                     \u001b[0;34m'You are passing a target array of shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m                     \u001b[0;34m' while using as loss `categorical_crossentropy`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m                     \u001b[0;34m'`categorical_crossentropy` expects '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m                     \u001b[0;34m'targets to be binary matrices (1s and 0s) '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: You are passing a target array of shape (4, 1) while using as loss `categorical_crossentropy`. `categorical_crossentropy` expects targets to be binary matrices (1s and 0s) of shape (samples, classes). If your targets are integer classes, you can convert them to the expected format via:\n```\nfrom keras.utils import to_categorical\ny_binary = to_categorical(y_int)\n```\n\nAlternatively, you can use the loss function `sparse_categorical_crossentropy` instead, which does expect integer targets."
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "7bExrx9X3DcK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Keras Optimizers\n",
        "\n",
        "**SGD - Stochastic Gradient Descent:** It uses the following paramters:\n",
        "* Learning rate.\n",
        "* Momentum\n",
        "* Nesterov Momentum (This slows down the gradient when it's close to the solution)\n",
        "\n",
        "**Adam:** Adaptive Moment Estimation uses a more complicated exponential decay that consists of not just considering the average (first moment), but also the variance (second moment) of the previous steps.\n",
        "\n",
        "**RMSProp:** RMSProp (RMS stands for Roo Mean Square Error) decreases the learning rate by dividing it by an exponentially decaying average of squared gradients.\n",
        "\n",
        "[Further explanation of Keras Optimizers](http://ruder.io/optimizing-gradient-descent/index.html#rmsprop)\n",
        "\n",
        "[Keras Documentation about Optimizers](https://keras.io/optimizers/)"
      ]
    },
    {
      "metadata": {
        "id": "JPauE_rn46um",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### IMDB Data in Keras"
      ]
    },
    {
      "metadata": {
        "id": "xcEO0dUS4W90",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "75e6a36c-b789-4dd3-a0bf-0a9f6238f0c2",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526322337437,
          "user_tz": -120,
          "elapsed": 6964,
          "user": {
            "displayName": "Matthias Ludwig",
            "photoUrl": "//lh3.googleusercontent.com/-Cacxebueg8s/AAAAAAAAAAI/AAAAAAAAAM8/S7I83k3nq90/s50-c-k-no/photo.jpg",
            "userId": "109901656152479831667"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.datasets import imdb\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "# Loading the data\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=1000)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 1s 0us/step\n",
            "(25000,)\n",
            "(25000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1220nLwD5m3i",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "2db8ddd2-bc9f-43cd-9ff8-0e0bc0e14fbd",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526322386370,
          "user_tz": -120,
          "elapsed": 684,
          "user": {
            "displayName": "Matthias Ludwig",
            "photoUrl": "//lh3.googleusercontent.com/-Cacxebueg8s/AAAAAAAAAAI/AAAAAAAAAM8/S7I83k3nq90/s50-c-k-no/photo.jpg",
            "userId": "109901656152479831667"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "print(x_train[0])\n",
        "print(x_test[0])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 14, 22, 16, 43, 530, 973, 2, 2, 65, 458, 2, 66, 2, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 2, 2, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2, 19, 14, 22, 4, 2, 2, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 2, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2, 2, 16, 480, 66, 2, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 2, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 2, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 2, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 2, 88, 12, 16, 283, 5, 16, 2, 113, 103, 32, 15, 16, 2, 19, 178, 32]\n",
            "[1, 591, 202, 14, 31, 6, 717, 10, 10, 2, 2, 5, 4, 360, 7, 4, 177, 2, 394, 354, 4, 123, 9, 2, 2, 2, 10, 10, 13, 92, 124, 89, 488, 2, 100, 28, 2, 14, 31, 23, 27, 2, 29, 220, 468, 8, 124, 14, 286, 170, 8, 157, 46, 5, 27, 239, 16, 179, 2, 38, 32, 25, 2, 451, 202, 14, 6, 717]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ypg-wpBr51Jf",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 746
        },
        "outputId": "e80b1996-5522-4329-9975-a580256d490e",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526322449077,
          "user_tz": -120,
          "elapsed": 4699,
          "user": {
            "displayName": "Matthias Ludwig",
            "photoUrl": "//lh3.googleusercontent.com/-Cacxebueg8s/AAAAAAAAAAI/AAAAAAAAAM8/S7I83k3nq90/s50-c-k-no/photo.jpg",
            "userId": "109901656152479831667"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# One-hot encoding the output into vector mode, each of length 1000\n",
        "tokenizer = Tokenizer(num_words=1000)\n",
        "x_train = tokenizer.sequences_to_matrix(x_train, mode='binary')\n",
        "x_test = tokenizer.sequences_to_matrix(x_test, mode='binary')\n",
        "print(x_train[0])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0.\n",
            " 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0.\n",
            " 1. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0.\n",
            " 0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0.\n",
            " 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0.\n",
            " 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
            " 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KtO8E48j6Ddu",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "570da064-d6a9-4fb6-dc6f-f2172c0fbcf3",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526322493921,
          "user_tz": -120,
          "elapsed": 597,
          "user": {
            "displayName": "Matthias Ludwig",
            "photoUrl": "//lh3.googleusercontent.com/-Cacxebueg8s/AAAAAAAAAAI/AAAAAAAAAM8/S7I83k3nq90/s50-c-k-no/photo.jpg",
            "userId": "109901656152479831667"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# One-hot encoding the output\n",
        "num_classes = 2\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(25000, 2)\n",
            "(25000, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jHnx8xKl6Pam",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "outputId": "d062d0af-8c6a-4290-eddc-fc371466ac59",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526322960224,
          "user_tz": -120,
          "elapsed": 673,
          "user": {
            "displayName": "Matthias Ludwig",
            "photoUrl": "//lh3.googleusercontent.com/-Cacxebueg8s/AAAAAAAAAAI/AAAAAAAAAM8/S7I83k3nq90/s50-c-k-no/photo.jpg",
            "userId": "109901656152479831667"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Build the model architecture\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(265, input_dim=x_train.shape[1]))\n",
        "model.add(Activation('sigmoid'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(128))\n",
        "model.add(Activation('sigmoid'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(2))\n",
        "# TODO: Compile the model using a loss function and an optimizer.\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics = [\"accuracy\"])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_22 (Dense)             (None, 265)               265265    \n",
            "_________________________________________________________________\n",
            "activation_21 (Activation)   (None, 265)               0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 265)               0         \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 128)               34048     \n",
            "_________________________________________________________________\n",
            "activation_22 (Activation)   (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 2)                 258       \n",
            "=================================================================\n",
            "Total params: 299,571\n",
            "Trainable params: 299,571\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2uVX7djx7m3m",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 1400
        },
        "outputId": "6c077dff-b11b-4aee-9794-d0820c094271",
        "executionInfo": {
          "status": "error",
          "timestamp": 1526323345314,
          "user_tz": -120,
          "elapsed": 383912,
          "user": {
            "displayName": "Matthias Ludwig",
            "photoUrl": "//lh3.googleusercontent.com/-Cacxebueg8s/AAAAAAAAAAI/AAAAAAAAAM8/S7I83k3nq90/s50-c-k-no/photo.jpg",
            "userId": "109901656152479831667"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train, epochs=1000, verbose=0)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-15f114b4eb02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1000\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "ftaOjvxy7uqq",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Evaluating the model\n",
        "\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Accuracy: \", score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}